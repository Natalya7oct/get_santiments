{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4310d938",
      "metadata": {
        "id": "4310d938"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, MaxPooling1D, Conv1D, GlobalMaxPooling1D, Dropout, SimpleRNN\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from wordcloud import WordCloud\n",
        "import emoji\n",
        "import string\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "from contextlib import contextmanager\n",
        "import sys, os\n",
        "\n",
        "@contextmanager\n",
        "def suppress_stdout():\n",
        "    with open(os.devnull, \"w\") as devnull:\n",
        "        old_stdout = sys.stdout\n",
        "        sys.stdout = devnull\n",
        "        try:\n",
        "            yield\n",
        "        finally:\n",
        "            sys.stdout = old_stdout\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b5976ea",
      "metadata": {
        "id": "0b5976ea"
      },
      "outputs": [],
      "source": [
        "from dateutil import parser as dtparser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2e3185e",
      "metadata": {
        "id": "b2e3185e"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1fe19de",
      "metadata": {
        "id": "d1fe19de"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5baf649f",
      "metadata": {
        "id": "5baf649f"
      },
      "outputs": [],
      "source": [
        "from datetime import timedelta, date\n",
        "import pyodbc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19fec12f",
      "metadata": {
        "id": "19fec12f"
      },
      "outputs": [],
      "source": [
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64eb3cfe",
      "metadata": {
        "id": "64eb3cfe"
      },
      "outputs": [],
      "source": [
        "from concurrent.futures import ProcessPoolExecutor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f0944a3",
      "metadata": {
        "id": "2f0944a3"
      },
      "outputs": [],
      "source": [
        "stopwords = stopwords.words(\"russian\")\n",
        "morph = pymorphy2.MorphAnalyzer(lang='ru')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df52281d",
      "metadata": {
        "id": "df52281d"
      },
      "outputs": [],
      "source": [
        "def sep_smiles(x):\n",
        "    x=str(x)\n",
        "    smile = re.findall(r'\\){1,}', x)\n",
        "    sad = re.findall(r'\\({1,}', x)\n",
        "    emojis = emoji.distinct_emoji_list(x)\n",
        "    for word in smile:\n",
        "        new_word=' '+'üôÇ'+' '\n",
        "        x=x.replace(word, new_word)\n",
        "    for word in sad:\n",
        "        new_word=' '+'üòû'+' '\n",
        "        x=x.replace(word, new_word)\n",
        "    for word in smile+sad+emojis:\n",
        "        new_word=' '+word+' '\n",
        "        x=x.replace(word, new_word)\n",
        "    return(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a83679cd",
      "metadata": {
        "id": "a83679cd"
      },
      "outputs": [],
      "source": [
        "def clean(text):\n",
        "  text=str(text)\n",
        "  text = re.sub(r'[:;]', '', text)\n",
        "  text=sep_smiles(text)\n",
        "  xxx = re.findall(r'X{1,}', text)\n",
        "  words = text.split(' ')\n",
        "  new_words = []\n",
        "  for word in words:\n",
        "    if (word not in stopwords and word not in xxx):\n",
        "      new_words.append(word)\n",
        "  result=' '.join(new_words)\n",
        "  result=\" \".join(result.split())\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ce70e6e",
      "metadata": {
        "id": "5ce70e6e"
      },
      "outputs": [],
      "source": [
        "saved_model_path_neg = '/tmp/tf_save_neg'\n",
        "saved_model_path_pos = '/tmp/tf_save_pos'\n",
        "load_options = tensorflow.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n",
        "model_rnn_neg = tensorflow.keras.models.load_model(saved_model_path_neg, options=load_options)\n",
        "model_rnn_pos = tensorflow.keras.models.load_model(saved_model_path_pos, options=load_options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f786c039",
      "metadata": {
        "id": "f786c039"
      },
      "outputs": [],
      "source": [
        "def sent(text,neg_treshold,pos_treshold):\n",
        "    text=clean(text)\n",
        "    text=' '.join([morph.parse(word)[0]. normal_form for word in text.split()])\n",
        "    sequence = tokenizer.texts_to_sequences([text])\n",
        "    data = pad_sequences(sequence, maxlen=max_review_len)\n",
        "    result_neg = model_rnn_neg.predict(data)\n",
        "    result_pos = model_rnn_pos.predict(data)\n",
        "    sent = new_label(result_neg,result_pos,neg_treshold,pos_treshold)\n",
        "    return(sent,result_neg,result_pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93472d9c",
      "metadata": {
        "id": "93472d9c"
      },
      "outputs": [],
      "source": [
        "def new_label(pred_neg,pred_pos,neg_treshold,pos_treshold):\n",
        "    if (pred_neg<neg_treshold and pred_pos<pos_treshold):\n",
        "        label=0\n",
        "    elif (pred_neg>=neg_treshold):\n",
        "        label=-1\n",
        "    elif (pred_pos>=pos_treshold):\n",
        "        label=1\n",
        "    else:\n",
        "        label=0\n",
        "    return(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "162f3d0c",
      "metadata": {
        "id": "162f3d0c"
      },
      "outputs": [],
      "source": [
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0744320a",
      "metadata": {
        "id": "0744320a"
      },
      "outputs": [],
      "source": [
        "num_words = 10000\n",
        "max_review_len = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38ce198f",
      "metadata": {
        "id": "38ce198f",
        "outputId": "ef4466c5-c697-41ca-c3b0-1f5b96125f00",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 328ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text='—Å–ø–∞—Å–∏–±–æ —ç—Ç–æ –±—ã–ª–æ –æ—Ö—É–µ–Ω–Ω–æ'\n",
        "sent(text,0.6,0.85)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cd6bfbf",
      "metadata": {
        "id": "0cd6bfbf"
      },
      "outputs": [],
      "source": [
        "def daterange(start_date, end_date):\n",
        "    for n in range(int ((end_date - start_date).days)):\n",
        "        yield start_date + timedelta(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65490fd3",
      "metadata": {
        "id": "65490fd3",
        "outputId": "0d4893bb-54c9-452e-a0b5-8755b8b8327e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-04-23 0 500\n",
            "2023-04-23 1 500\n",
            "2023-04-23 2 500\n",
            "2023-04-23 3 500\n",
            "2023-04-23 4 500\n",
            "2023-04-23 5 500\n",
            "2023-04-23 6 500\n",
            "2023-04-23 7 500\n",
            "2023-04-23 8 500\n",
            "2023-04-23 9 500\n",
            "2023-04-23 10 500\n",
            "2023-04-23 11 500\n",
            "2023-04-23 12 500\n",
            "2023-04-23 13 500\n",
            "2023-04-23 14 500\n",
            "2023-04-23 15 500\n",
            "2023-04-23 16 500\n",
            "2023-04-23 17 500\n",
            "2023-04-23 18 500\n",
            "2023-04-23 19 500\n",
            "2023-04-23 20 500\n",
            "2023-04-23 21 500\n",
            "2023-04-23 22 500\n",
            "2023-04-23 23 500\n",
            "0:00:51.023012\n",
            "2023-04-23\n",
            "2023-04-24 0 500\n",
            "2023-04-24 1 500\n",
            "2023-04-24 2 500\n",
            "2023-04-24 3 500\n",
            "2023-04-24 4 500\n",
            "2023-04-24 5 500\n",
            "2023-04-24 6 500\n",
            "2023-04-24 7 500\n",
            "2023-04-24 8 500\n",
            "2023-04-24 9 500\n",
            "2023-04-24 10 500\n",
            "2023-04-24 11 500\n",
            "2023-04-24 12 500\n",
            "2023-04-24 13 500\n",
            "2023-04-24 14 500\n",
            "2023-04-24 15 500\n",
            "2023-04-24 16 500\n",
            "2023-04-24 17 500\n",
            "2023-04-24 18 500\n",
            "2023-04-24 19 500\n",
            "2023-04-24 20 500\n",
            "2023-04-24 21 500\n",
            "2023-04-24 22 500\n",
            "2023-04-24 23 500\n",
            "0:00:51.133529\n",
            "2023-04-24\n",
            "2023-04-25 0 500\n",
            "2023-04-25 1 500\n",
            "2023-04-25 2 500\n",
            "2023-04-25 3 500\n",
            "2023-04-25 4 500\n",
            "2023-04-25 5 500\n",
            "2023-04-25 6 500\n",
            "2023-04-25 7 500\n",
            "2023-04-25 8 500\n",
            "2023-04-25 9 500\n",
            "2023-04-25 10 500\n",
            "2023-04-25 11 500\n",
            "2023-04-25 12 500\n",
            "2023-04-25 13 500\n",
            "2023-04-25 14 500\n",
            "2023-04-25 15 500\n",
            "2023-04-25 16 500\n",
            "2023-04-25 17 500\n",
            "2023-04-25 18 500\n",
            "2023-04-25 19 500\n",
            "2023-04-25 20 500\n",
            "2023-04-25 21 500\n",
            "2023-04-25 22 500\n",
            "2023-04-25 23 500\n",
            "0:06:58.326746\n",
            "2023-04-25\n",
            "2023-04-26 0 500\n",
            "2023-04-26 1 500\n",
            "2023-04-26 2 500\n",
            "2023-04-26 3 500\n",
            "2023-04-26 4 500\n",
            "2023-04-26 5 500\n",
            "2023-04-26 6 500\n",
            "2023-04-26 7 500\n",
            "2023-04-26 8 500\n",
            "2023-04-26 9 500\n",
            "2023-04-26 10 500\n",
            "2023-04-26 11 500\n",
            "2023-04-26 12 500\n",
            "2023-04-26 13 500\n",
            "2023-04-26 14 500\n"
          ]
        },
        {
          "ename": "Error",
          "evalue": "('01000', '[01000] [Microsoft][ODBC SQL Server Driver][DBNETLIB]ConnectionWrite (send()). (10054) (SQLExecDirectW); [01000] [Microsoft][ODBC SQL Server Driver][DBNETLIB]–û–±—â–∞—è –æ—à–∏–±–∫–∞ —Å–µ—Ç–∏. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–æ —Å–µ—Ç–∏. (11)')",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_876/559329205.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             cursor.execute(\"INSERT INTO [ChatBotData].[report].[message_status_sentiment] (Date,SessionID,MessageID,Sentiment) \\\n\u001b[0m\u001b[0;32m     60\u001b[0m             values(?,?,?,?)\", row.Time,row.SessionID,row.MessageID,row.Sentiment)\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mError\u001b[0m: ('01000', '[01000] [Microsoft][ODBC SQL Server Driver][DBNETLIB]ConnectionWrite (send()). (10054) (SQLExecDirectW); [01000] [Microsoft][ODBC SQL Server Driver][DBNETLIB]–û–±—â–∞—è –æ—à–∏–±–∫–∞ —Å–µ—Ç–∏. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–æ —Å–µ—Ç–∏. (11)')"
          ]
        }
      ],
      "source": [
        "start_date = date(2023, 4, 23)\n",
        "end_date = date(2023, 4, 30)\n",
        "\n",
        "\n",
        "for single_date in daterange(start_date, end_date):\n",
        "\n",
        "    date=single_date.strftime(\"%Y-%m-%d\")\n",
        "    starttime = datetime.now()\n",
        "\n",
        "\n",
        "    for h in range(24):\n",
        "\n",
        "        server = ''\n",
        "        database = ''\n",
        "        username = ''\n",
        "        password = ''\n",
        "        driver= 'SQL Server'\n",
        "\n",
        "        connection = pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password)\n",
        "\n",
        "\n",
        "\n",
        "        requestString_sessions = f'''\n",
        "        select top 500 TimeStart as Time,SessionID,MessageID,PhraseText\n",
        "        from prd.PhraseData\n",
        "        where cast(TimeStart as date)='{date}'\n",
        "        and datepart(hour, TimeStart)={h}\n",
        "        and NlpModelName!='AM'\n",
        "        and len(PhraseText)>0\n",
        "        '''\n",
        "\n",
        "        #requestString_sessions = f'''\n",
        "        #Select Time, SessionID, MessageID, PhraseText from ChatBotData.report.PhraseData_Just pdj\n",
        "        #where cast(Time as date)='{date}' and datepart(hour, Time)={h} and PhraseText != ''\n",
        "        #'''\n",
        "\n",
        "        #requestString_sessions = f'''\n",
        "        #Select top 500 Time, SessionID, MessageID, PhraseText from ChatBotData.report.PhraseData_Just pdj\n",
        "        #where cast(Time as date)='{date}' and datepart(hour, Time)={h} and PhraseText != ''\n",
        "        #and MessageID not in\n",
        "            #(select MessageID from report.message_status_sentiment\n",
        "             #where cast(Date as date)='{date}' and datepart(hour, Date)={h}) '''\n",
        "\n",
        "        df = pd.read_sql_query(requestString_sessions,connection)\n",
        "\n",
        "        starttime = datetime.now()\n",
        "        df['Sentiment']=0\n",
        "\n",
        "        with suppress_stdout():\n",
        "            for i in range(len(df)):\n",
        "                text=df['PhraseText'].iloc[i]\n",
        "                s=sent(text,0.6,0.85)[0]\n",
        "                df['Sentiment'].iloc[i]=s\n",
        "\n",
        "\n",
        "        cursor = connection.cursor()\n",
        "\n",
        "        for index, row in df.iterrows():\n",
        "            cursor.execute(\"INSERT INTO [ChatBotData].[report].[message_status_sentiment] (Date,SessionID,MessageID,Sentiment) \\\n",
        "            values(?,?,?,?)\", row.Time,row.SessionID,row.MessageID,row.Sentiment)\n",
        "\n",
        "        print(date,h,len(df))\n",
        "\n",
        "        connection.commit()\n",
        "        cursor.close()\n",
        "\n",
        "    print(datetime.now() - starttime)\n",
        "    print(date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a707234",
      "metadata": {
        "id": "5a707234"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd3f77da",
      "metadata": {
        "id": "dd3f77da"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d722291",
      "metadata": {
        "id": "4d722291"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee0d57ac",
      "metadata": {
        "id": "ee0d57ac"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33971372",
      "metadata": {
        "id": "33971372"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "157c2ab7",
      "metadata": {
        "id": "157c2ab7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0db161c",
      "metadata": {
        "id": "f0db161c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7aaf821",
      "metadata": {
        "id": "c7aaf821"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5c73271",
      "metadata": {
        "id": "c5c73271"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1926739e",
      "metadata": {
        "id": "1926739e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "395879a7",
      "metadata": {
        "id": "395879a7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1585e437",
      "metadata": {
        "id": "1585e437"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}